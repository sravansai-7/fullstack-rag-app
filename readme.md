# Full-Stack RAG Q&A Application üìöü§ñ

This project is a complete full-stack web application that implements a Retrieval-Augmented Generation (RAG) pipeline. It allows users to ask questions in natural language about a specific document and receive accurate, context-aware answers generated by Google's Gemini model.

It features a secure Python/Flask backend that handles the AI logic and a modern React/Vite frontend for a smooth user experience.

[Image of the RAG Q&A application UI]

---

## **Features**

* **Accurate, Document-Grounded Q&A**: Answers are generated based on a specific source document, preventing hallucinations.
* **Modern React UI**: A clean, responsive user interface with real-time loading and error feedback.
* **Secure Python Backend**: The backend, built with Flask, securely manages the Google API key and all AI processing.
* **Efficient In-Memory Vector Search**: Uses FAISS for fast and efficient similarity searches directly in memory.

---

## **How It Works: The RAG Pipeline**

This application follows a two-phase RAG process:

1. **Indexing (On Startup)**: When the backend server starts, it loads the `my_document.txt` file, splits it into smaller text chunks, and uses Google's embedding model to convert each chunk into a vector. These vectors are then stored in a FAISS in-memory vector store, creating a searchable knowledge base.

2. **Retrieval & Generation (On Query)**: When you ask a question, the backend embeds your query into a vector, searches the FAISS store for the most relevant text chunks, and then passes both your question and the retrieved chunks to the Gemini model. This provides the model with the necessary context to generate a highly relevant and accurate answer.

---

## **Tech Stack** ‚öôÔ∏è

* **Frontend**:
  * [React](https://reactjs.org/)
  * [Vite](https://vitejs.dev/)
  * CSS3
* **Backend**:
  * [Python](https://www.python.org/)
  * [Flask](https://flask.palletsprojects.com/)
  * [LangChain](<https://python.langchain>.
